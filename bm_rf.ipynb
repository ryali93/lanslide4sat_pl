{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the processed data\n",
    "TRAIN_XX = np.load('TrainData_prep/TRAIN_XX_11var.npy')\n",
    "TRAIN_YY = np.load('TrainData_prep/TRAIN_YY_11var.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3799, 11)\n",
      "(128, 128, 3799, 1)\n"
     ]
    }
   ],
   "source": [
    "#reorder the axis for test_train_split\n",
    "X = np.moveaxis(TRAIN_XX, 0, 2)\n",
    "print(X.shape)\n",
    "y = np.moveaxis(TRAIN_YY, 0, 2)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  : 60800026\n",
      "1.0  : 1442790\n",
      "tot  : 62242816\n",
      "class 1 proportion: 2.32 %\n"
     ]
    }
   ],
   "source": [
    "#Check the frequency of each class and the proportion of class 1\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique[0], \" :\", counts[0])\n",
    "print(unique[1], \" :\", counts[1])\n",
    "toti = counts[0] + counts[1]\n",
    "class1_prop = counts[1] / toti\n",
    "print(\"tot  :\", toti)\n",
    "print(\"class 1 proportion: {:.2f} %\".format(class1_prop * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  3  4  5  6  7  8  9 10]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Create an array which holds each image index which have landslide presence\n",
    "result = np.where(y == 1)[2]\n",
    "result_sort = np.sort(result)\n",
    "result_sort = np.unique(result_sort)\n",
    "print(result_sort[:10])\n",
    "\n",
    "#Create an array \"y_strat\" which will hold the length of 3799 and a 0 indexed for each image without landslide and a 1 for each with landslide \n",
    "# (To enable stratify in test_train_split).\n",
    "y_strat = np.zeros(3799)\n",
    "for i, v in enumerate(result_sort):\n",
    "    y_strat[v] = 1\n",
    "print(y_strat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 2849, 11) (128, 128, 950, 11)\n",
      "(128, 128, 2849, 1) (128, 128, 950, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into test, train while preserving the image shapes\n",
    "from sklearn.model_selection import train_test_split\n",
    "all_indices = list(range(3799))\n",
    "train_ind, test_ind = train_test_split(all_indices,  random_state=0, shuffle=True, stratify=y_strat)\n",
    "\n",
    "X_train_dummy = X[:,:,train_ind,:]\n",
    "X_test_dummy = X[:,:,test_ind, :]\n",
    "\n",
    "y_train_dummy = y[:,:,train_ind,:]\n",
    "y_test_dummy = y[:,:,test_ind, :]\n",
    "\n",
    "print(X_train_dummy.shape, X_test_dummy.shape)\n",
    "print(y_train_dummy.shape, y_test_dummy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18528/1099634591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_train_dummy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"new X_train shape: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32me:\\2020\\maestria\\ciclo_04\\venv\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \"\"\"\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mARRAY_FUNCTION_ENABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;31m# raise warning if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Stack the X datasets into 2d arrays to fit the model\n",
    "X_train = np.vstack((X_train_dummy[0]))\n",
    "for i in X_train_dummy[1:]:\n",
    "    X_train = np.concatenate((X_train,np.vstack((i))),axis=0)\n",
    "print(\"new X_train shape: {}\".format(X_train.shape))\n",
    "\n",
    "X_test = np.vstack((X_test_dummy[0]))\n",
    "for i in X_test_dummy[1:]:\n",
    "    X_test = np.concatenate((X_test,np.vstack((i))),axis=0)\n",
    "print(\"new X_test shape: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the y datasets into 1d arrays to fit the model\n",
    "y_train = np.vstack((y_train_dummy[0]))\n",
    "for i in y_train_dummy[1:]:\n",
    "    y_train = np.concatenate((y_train,np.vstack((i))),axis=0)\n",
    "y_train = y_train.reshape(-1)\n",
    "print(\"new y_train shape: {}\".format(y_train.shape))\n",
    "\n",
    "y_test = np.vstack((y_test_dummy[0]))\n",
    "for i in y_test_dummy [1:]:\n",
    "    y_test = np.concatenate((y_test,np.vstack((i))),axis=0)\n",
    "y_test = y_test.reshape(-1)\n",
    "print(\"new y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the imbalanced distribution between 0's and 1's a RandomUnderSampler is performed.\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "# Randomly under sample the majority class (0's)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus= rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the resampled distribution between the two classes\n",
    "unique, counts = np.unique(y_train_rus, return_counts=True)\n",
    "print(unique[0], \" :\", counts[0])\n",
    "print(unique[1], \" :\", counts[1])\n",
    "toti = counts[0] + counts[1]\n",
    "class1_prop = counts[1] / toti\n",
    "print(\"tot  :\", toti)\n",
    "print(\"class 1 proportion: {:.2f} %\".format(class1_prop * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the stacked train/test datasets\n",
    "print(\"X_train_rus shape:\", X_train_rus.shape)\n",
    "print(\"y_train_rus shape:\", y_train_rus.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Random Forest Classifier with 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0, verbose=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "rfc.fit(X_train_rus, y_train_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the prediction of the test dataset, first\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(\"True Positive: \", confusion_matrix(y_test,y_pred)[0][0])\n",
    "print(\"False Negative: \", confusion_matrix(y_test,y_pred)[0][1])\n",
    "print(\"False Positive: \", confusion_matrix(y_test,y_pred)[1][0])\n",
    "print(\"True Negative: \", confusion_matrix(y_test,y_pred)[1][1])\n",
    "print(\"\\nClassification Report: \\n\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Due to the skewness between precision and recall the threshold is set to 0.95, it worsens precision but improves recall\n",
    "threshold = 0.95\n",
    "predicted_proba = rfc.predict_proba(X_test)\n",
    "y_pred = (predicted_proba [:,1] >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the prediction of the test dataset, second\n",
    "#With a changed threshold we receive a better f1-score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(\"True Positive: \", confusion_matrix(y_test,y_pred)[0][0])\n",
    "print(\"False Negative: \", confusion_matrix(y_test,y_pred)[0][1])\n",
    "print(\"False Positive: \", confusion_matrix(y_test,y_pred)[1][0])\n",
    "print(\"True Negative: \", confusion_matrix(y_test,y_pred)[1][1])\n",
    "print(\"\\nClassification Report: \\n\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list containing each feature name\n",
    "feature_names = ['RED', 'GREEN', 'BLUE', 'NDVI', 'SLOPE', 'ELEVATION', 'NDMI', 'GNDVI', 'BAND 10', 'BRIGHTNESS', 'BSI']\n",
    "print(len(feature_names))\n",
    "\n",
    "#Extract feature importance and std\n",
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "#Plot the feature importance\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restore the predicted data into images of size 128x128\n",
    "y_pred_reshaped = y_pred.reshape(128, 128, 950, 1)\n",
    "print(y_pred_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the most important features, the ground truth and the predicted output of an example image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True, figsize=(15,7))\n",
    "ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10 = axes.flatten()\n",
    "\n",
    "ax1.set_title(\"RGB\", fontweight='bold', fontsize='16')\n",
    "ax1.imshow(X_test_dummy[:,:,40,0:3])\n",
    "\n",
    "ax2.set_title(\"NDVI\", fontweight='bold', fontsize='16')\n",
    "ax2.imshow(X_test_dummy[:,:,40,3], cmap='gist_rainbow')\n",
    "\n",
    "ax3.set_title(\"SLOPE\", fontweight='bold', fontsize='16')\n",
    "ax3.imshow(X_test_dummy[:,:,40,4], cmap='gist_rainbow')\n",
    "\n",
    "ax4.set_title(\"ELEVATION\", fontweight='bold', fontsize='16')\n",
    "ax4.imshow(X_test_dummy[:,:,40,5], cmap='gist_rainbow')\n",
    "\n",
    "ax5.set_title(\"NDMI\", fontweight='bold', fontsize='16')\n",
    "ax5.imshow(X_test_dummy[:,:,40,6], cmap='coolwarm_r')\n",
    "\n",
    "ax6.set_title(\"GNDVI\", fontweight='bold', fontsize='16')\n",
    "ax6.imshow(X_test_dummy[:,:,40,7], cmap='gist_rainbow')\n",
    "\n",
    "ax7.set_title(\"Brightness\", fontweight='bold', fontsize='16')\n",
    "ax7.imshow(X_test_dummy[:,:,40,9], cmap='gist_rainbow')\n",
    "\n",
    "ax8.set_title(\"BSI\", fontweight='bold', fontsize='16')\n",
    "ax8.imshow(X_test_dummy[:,:,40,10], cmap='gist_rainbow')\n",
    "\n",
    "ax9.set_title(\"Ground Truth\", fontweight='bold', fontsize='16')\n",
    "ax9.imshow(y_test_dummy[:,:,40,:])\n",
    "\n",
    "ax10.set_title(\"Predicted\", fontweight='bold', fontsize='16')\n",
    "ax10.imshow(y_pred_reshaped[:,:,40,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d22842d54a7ea5f16f58a4e56a58ac8809f2e07dd9359b04312ace11248964c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
